{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4faaa1cc",
   "metadata": {},
   "source": [
    "卷积神经网络注重使用空间中的不变性\n",
    "\n",
    "平移不变性（translation invariance）：不管检测对象出现在图像中的哪个位置，神经网络的前面几层应该对相同的图像区域具有相似的反应，即为“平移不变性”。\n",
    "局部性（locality）：神经网络的前面几层应该只探索输入图像中的局部区域，而不过度在意图像中相隔较远区域的关系，这就是“局部性”原则。最终，可以聚合这些局部特征，以在整个图像级别进行预测。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339aaa50",
   "metadata": {},
   "source": [
    "上述关于卷积核的概念仅仅在于二维卷积核，也就是关于平面图像，我们有了这样的想法\n",
    "\n",
    "但是对于一般的彩色图像，其中往往包含三个通道/三种原色（红、绿、蓝）\n",
    "因此图像实际上并不只是一个二维张量，而是一个由高度、宽度和颜色组成的三维张量\n",
    "\n",
    "于是对于图中的输入特征，可以看作是前两个轴与像素的空间位置有关，而第三个轴可以看作每个像素的多维表示\n",
    "从而对应的卷积和隐藏表示都同样修改为三维张量\n",
    "\n",
    "换句话说，对于每一个空间位置，我们想要采用一组而不是一个隐藏表示。这样一组隐藏表示可以想象成一些互相堆叠的二维网格。 因此，我们可以把隐藏表示想象为一系列具有二维张量的通道（channel）。 这些通道有时也被称为特征映射（feature maps），因为每个通道都向后续层提供一组空间化的学习特征。 "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
