{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0319e47",
   "metadata": {},
   "source": [
    "到目前为止，已经反复提到像梯度爆炸或梯度消失，以及需要对循环神经网络分离梯度，例如，在 8.5节中，我们在序列上调用了detach函数。\n",
    "\n",
    "梯度截断对于确保模型收敛至关重要\n",
    "\n",
    "循环神经网络中的前向传播相对简单。通过时间反向传播（backpropagation through time，BPTT） (Werbos, 1990)实际上是循环神经网络中反向传播技术的一个特定应用。 \n",
    "它要求我们将循环神经网络的计算图一次展开一个时间步，以获得模型变量和参数之间的依赖关系。 然后，基于链式法则，应用反向传播来计算和存储梯度。 \n",
    "由于序列可能相当长，因此依赖关系也可能相当长。 例如，某个1000个字符的序列， 其第一个词元可能会对最后位置的词元产生重大影响，但这在计算上是不可行的（它需要的时间和内存都太多了）， 并且还需要超过1000个矩阵的乘积才能得到非常难以捉摸的梯度。 \n",
    "这个过程充满了计算与统计的不确定性，在下文中，我们将阐明会发生什么以及如何在实践中解决它们。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62185df4",
   "metadata": {},
   "source": [
    "具体的公式推导可以查看原网站\n",
    "\n",
    "简单来说，对于得到的式子，可以发现其梯度相关的链可能会变得很长，因此这样的计算可能会非常缓慢，并且可能发生梯度爆炸，因为初始条件的微小变化就可能对结果产生巨大的影响\n",
    "\n",
    "类似地，可以考虑通过截断时间步的方式来作为真实梯度的近似，除了固定时间步的截断外，也可以采用随机截断，但效果似乎没有比常规阶段更好"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
