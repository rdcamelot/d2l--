{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4df3989d",
   "metadata": {},
   "source": [
    "同样可以通过API来实现softmax回归模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1a0069c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l\n",
    "\n",
    "batch_size = 256\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bdc0bd",
   "metadata": {},
   "source": [
    "初始化模型参数\n",
    "\n",
    "这里使用nn.Sequential创建模型，它是一个有序的模块容器，模块将按照定义的顺序被添加到计算图中：\n",
    "展平层 (nn.Flatten):\n",
    "    输入的图像是28×28像素的二维图像\n",
    "    展平层将每个样本从形状为(batch_size, 1, 28, 28)的张量转换为形状为(batch_size, 784)的张量\n",
    "    这是必要的，因为全连接层需要一维输入\n",
    "\n",
    "全连接层 (nn.Linear(784, 10)):\n",
    "    输入特征数为784（展平后的图像像素数）\n",
    "    输出特征数为10（对应10个类别）\n",
    "    这个层自动包含权重矩阵和偏置向量，对应于手动实现中的W和b\n",
    "    数学上，实现了变换：y = Wx + b\n",
    "    在softmax回归中，这个线性变换的结果将被用来计算类别概率\n",
    "\n",
    "在这个softmax回归模型中，全连接层既是唯一的计算层，也是输出层\n",
    "\n",
    "展平层在网络中的位置\n",
    "    展平层通常位于卷积层/输入层之后，全连接层之前\n",
    "    它不是真正意义上的\"输入层\"，而是一个形状转换层\n",
    "    它没有可学习的参数，只改变数据布局\n",
    "\n",
    "输入图像 [256, 1, 28, 28]\n",
    "    ↓\n",
    "展平层：形状转换\n",
    "    ↓\n",
    "展平后 [256, 784]\n",
    "    ↓\n",
    "全连接层：线性变换 (W: [784, 10], b: [10])\n",
    "    ↓\n",
    "输出 [256, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c6d496b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch不会隐式地调整输入的形状。因此，\n",
    "# 我们在线性层前定义了展平层（flatten），来调整网络输入的形状\n",
    "net = nn.Sequential(nn.Flatten(), nn.Linear(784, 10))\n",
    "\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.normal_(m.weight, std=0.01)\n",
    "\n",
    "net.apply(init_weights);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd674b08",
   "metadata": {},
   "source": [
    "在交叉熵损失函数中传递未规范化的预测，并同时计算softmax及其对数， 这是一种类似“LogSumExp技巧”的方式。\n",
    "\n",
    "能避免上下溢问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd73ada1",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss(reduction='none')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6161c37e",
   "metadata": {},
   "source": [
    "优化算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f370426",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = torch.optim.SGD(net.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5cbb25b",
   "metadata": {},
   "source": [
    "训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41b29b39",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Animator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtrain_ch3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[5], line 4\u001b[0m, in \u001b[0;36mtrain_ch3\u001b[1;34m(net, train_iter, test_iter, loss, num_epochs, updater)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"训练模型（定义见第3章）\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# 实时可视化训练过程\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m animator \u001b[38;5;241m=\u001b[39m \u001b[43mAnimator\u001b[49m(xlabel\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m, xlim\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m1\u001b[39m, num_epochs], ylim\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0.3\u001b[39m, \u001b[38;5;241m0.9\u001b[39m],\n\u001b[0;32m      5\u001b[0m                     legend\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain loss\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain acc\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest acc\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m      7\u001b[0m     train_metrics \u001b[38;5;241m=\u001b[39m train_epoch_ch3(net, train_iter, loss, updater)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Animator' is not defined"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "train_ch3(net, train_iter, test_iter, loss, num_epochs, trainer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
